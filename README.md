# ğŸ–ï¸ Sign Language Detection Using Deep Learning

## ğŸ“Œ Overview
This project implements a **Sign Language Detection system** using **Deep Learning and Computer Vision**.  
A CNN model is trained to recognize hand gestures used in sign language from image data.

---

## ğŸ¯ Objectives
- Detect and classify sign language gestures  
- Train a CNN-based deep learning model  
- Apply image preprocessing techniques  
- Build a practical ML/DL project  

---

## ğŸ› ï¸ Technologies Used
- Python  
- TensorFlow / Keras  
- OpenCV  
- NumPy  
- Scikit-learn  
- Jupyter Notebook  

---

## ğŸ“‚ Project Structure
```text
SignLanguageDetector/
â”œâ”€â”€ README.md
â”œâ”€â”€ SignLanguageDetectorS.ipynb
â”œâ”€â”€ SignLanguageDetector.py
â””â”€â”€ SignLanguageCNN-small.h5
```
---

## ğŸ” Methodology

- Collected hand gesture image data
- Preprocessed images (resizing, normalization)
- Built a CNN model using convolution and pooling layers
- Trained the model on labeled gesture data
- Evaluated model performance using accuracy metrics
  
---

## ğŸ“Š Results

- The model successfully classifies sign language gestures  
- Achieved good accuracy on test data  
- Performs well on unseen hand gesture images  

---

## â–¶ï¸ How to Run the Project
**Clone the repository**

git clone https://github.com/zabeen-aslam/SignLanguageDetector.git
cd SignLanguageDetector

**Install dependencies**

pip install numpy opencv-python tensorflow scikit-learn   
Run the notebook   
jupyter notebook   
Open SignLanguageDetectorS.ipynb and run all cells.   

## ğŸš€ Future Improvements

- Real-time gesture detection using webcam
- Increase dataset size
- Support more sign language gestures
- Deploy as a web or mobile application

---
## ğŸ‘¤ Author

Zabeen Aslam
